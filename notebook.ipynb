{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ2g9mu7XgaP"
      },
      "source": [
        "Update currently installed packages in your Google Colab Notebook's runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SBIOlIUVgCN",
        "outputId": "ce532c35-2ccb-4873-db98-373951f1ffb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Wait\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 172 kB in 3s (60.9 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQlit156Ximj"
      },
      "source": [
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fR1jqw-bXTi9"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDZI6VnbXm3X"
      },
      "source": [
        "Next, we will download and unzip Apache Spark with Hadoop 2.7 to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tFRI6WpeXZEf"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XIrQT03XXbev"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm30koQnX3s6"
      },
      "source": [
        "Setup Environment variables for Java and Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MC4RxSkgX6GY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_bXY3DSZ8hu"
      },
      "source": [
        "Then we need to install and import the 'findspark' library that will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IA4WVVeiYHte"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4bobyzxZ9sq"
      },
      "source": [
        "Now, import SparkSession from pyspark.sql and create a SparkSession, which will be the entry point to Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W8KLz8knYU6t"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession \n",
        "\n",
        "spark = (SparkSession\n",
        "        .builder\n",
        "        .appName(\"datagrokr\")\n",
        "        .getOrCreate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzFZ2jYaGtl"
      },
      "source": [
        "Download all the files from Google drive link into the content directory of colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvnS2lHZ0qt",
        "outputId": "bf85e780-d0e2-457e-edf5-ea4ebd7b0b4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/chess/chess_schema.png',\n",
              " '/content/chess/chess_wc_history_game_info.csv',\n",
              " '/content/chess/chess_wc_history_moves.csv',\n",
              " '/content/chess/eco_codes.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7BWm7cocJS9"
      },
      "source": [
        "Create dataframes for each of the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ACah4HJkrgKF"
      },
      "outputs": [],
      "source": [
        "def head_view(dataframe):\n",
        "  dataframe.createOrReplaceTempView(\"tableHead\")\n",
        "  query = \"SELECT * FROM tableHead\"\n",
        "  df_head = spark.sql(query)\n",
        "  df_head.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I8NDjZiiL6y"
      },
      "source": [
        "Chess WC History Game Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HlkvPvxdbqNh"
      },
      "outputs": [],
      "source": [
        "df_games = spark.read.load(\"/content/chess/chess_wc_history_game_info.csv\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkaBhJ3NiOLS"
      },
      "source": [
        "Chess WC History Moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c256aub7hm59"
      },
      "outputs": [],
      "source": [
        "df_moves = spark.read.load(\"/content/chess/chess_wc_history_moves.csv\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuf3mxthumIO"
      },
      "source": [
        "WCh knock out(Sub-String with k.o. and KO ) are not included in main event. So, filter the event having Sub-String as k.o and KO in that specific Table Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZlqIkoh2nmrB"
      },
      "outputs": [],
      "source": [
        "df_games_notko = df_games.filter(~df_games.event.contains('k.o') | ~df_games.event.contains('KO'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u317P-naHtY"
      },
      "source": [
        "\n",
        "\n",
        "### 1Ô∏è‚É£ List of Winners of Each World champions Trophy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EgQYZX2Ch1wx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.functions import split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8EghM2Ml5V"
      },
      "source": [
        "Clean names of players - *select only first_name*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IlyjASmJRGzL"
      },
      "outputs": [],
      "source": [
        "def get_first_name(column):\n",
        "  return split(df_games_notko[column], ',').getItem(0)\n",
        "\n",
        "clean_names = ['white', 'black', 'winner', 'loser']\n",
        "for col in clean_names:\n",
        "  df_games_notko = df_games_notko.withColumn(col, get_first_name(col))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wwmTBZ9UAwlh"
      },
      "outputs": [],
      "source": [
        "def get_winner(dataframe):\n",
        "  white_players = dataframe.select('white').distinct().collect()\n",
        "  black_players = dataframe.select('black').distinct().collect()\n",
        "\n",
        "  players = set()\n",
        "  for player in white_players:\n",
        "    players.add(player.white)\n",
        "  for player in black_players:\n",
        "    players.add(player.black)\n",
        "\n",
        "  scores = dict.fromkeys(players, 0)\n",
        "  for game in dataframe.collect():\n",
        "    if game['result'] == 'draw':\n",
        "      scores[game['white']] += 1\n",
        "      scores[game['black']] += 1\n",
        "    elif game['result'] == '1-0':\n",
        "      scores[game['white']] += 1\n",
        "    else:\n",
        "      scores[game['black']] += 1\n",
        "      \n",
        "  return max(scores, key=scores.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ENdd1vxiaA4G"
      },
      "outputs": [],
      "source": [
        "all_tournaments = df_games_notko.toPandas().tournament_name.unique()\n",
        "\n",
        "result_list = []\n",
        "for tour in all_tournaments:\n",
        "  df_tour = df_games_notko.filter(df_games_notko.tournament_name == tour)\n",
        "  winner =  get_winner(df_tour)\n",
        "  result_list.append({'winner': winner, 'tournament_name': tour})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vE9-LkJyRDFy"
      },
      "outputs": [],
      "source": [
        "df1 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4nmi9zRqy6"
      },
      "source": [
        "### 2Ô∏è‚É£ List of Players with number of times they have won Tournament in descending order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "llldJ15sR33c"
      },
      "outputs": [],
      "source": [
        "df2 = df1.groupBy('winner').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAVqGu8VTrCv"
      },
      "source": [
        "### 3Ô∏è‚É£ Most and Least Popular eco move in world championship history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fo-qPfx2Tpej"
      },
      "outputs": [],
      "source": [
        "eco_counts = df_games_notko.groupBy('eco').count().toPandas()\n",
        "\n",
        "top = eco_counts.sort_values('count').head(1).values[0]\n",
        "end = eco_counts.sort_values('count').tail(1).values[0]\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'eco': end[0], 'eco_name': 'Double King Pawn Games', 'number_of_occurences': end[1]})\n",
        "result_list.append({'eco': top[0], 'eco_name': 'Sicilian Defence', 'number_of_occurences': top[1]})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3HLmDizM6S0i"
      },
      "outputs": [],
      "source": [
        "df3 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RjQhvbAJpd"
      },
      "source": [
        "### 4Ô∏è‚É£ Find the eco move with most winnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BavOoZeBAI7M"
      },
      "outputs": [],
      "source": [
        "df_games_notdraw = df_games_notko.filter(df_games_notko.result != 'draw')\n",
        "\n",
        "win_counts = df_games_notdraw.groupBy('eco').count().toPandas()\n",
        "\n",
        "top = win_counts.sort_values('count').head(1).values[0]\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'eco': top[0], 'eco_name': 'Sicilian Defence'})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1mv2zMeHEvJI"
      },
      "outputs": [],
      "source": [
        "df4 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEb9V6lXGWf6"
      },
      "source": [
        "### 5Ô∏è‚É£ Longest and shortest game ever played in a world championship in terms of move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "viTmrk7liKqO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nvBia1IDGjGZ"
      },
      "outputs": [],
      "source": [
        "def get_moves(game):\n",
        "  game_moves = df_moves.filter(df_moves.game_id == game)\n",
        "  return game_moves.agg(max('move_no')).collect()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NlZzSTGiFBy"
      },
      "outputs": [],
      "source": [
        "game_moves = []\n",
        "\n",
        "for game in df_games.collect():\n",
        "  moves = get_moves(game.game_id)\n",
        "  game_moves.append({'game_id': game.game_id, 'moves': moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(game_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gYLmTuamV_d"
      },
      "outputs": [],
      "source": [
        "longest = pandas_result.query('moves == moves.max()')\n",
        "shortest = pandas_result.query('moves == moves.min()')\n",
        "\n",
        "long_game = df_games.filter(df_games.game_id == longest.game_id)\n",
        "short_game = df_games.filter(df_games.game_id == shortest.game_id)\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'game_id': longest.game_id, 'event': long_game.event.collect()[0][0], 'tournament_name': long_game.tournament_name.collect()[0][0], 'number_of_moves': longest.moves})\n",
        "result_list.append({'game_id': shortest.game_id, 'event': short_game.event.collect()[0][0], 'tournament_name': short_game.tournament_name.collect()[0][0], 'number_of_moves': shortest.moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcI_s92goKoS"
      },
      "outputs": [],
      "source": [
        "df5 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz92TIrzoUaN"
      },
      "source": [
        "### 6Ô∏è‚É£ Shortest and Longest Draw game ever Played"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khkk__1XogdD"
      },
      "outputs": [],
      "source": [
        "game_moves = []\n",
        "\n",
        "games_drawn = df_games.filter(df_games.result == 'draw')\n",
        "\n",
        "for game in games_drawn.collect():\n",
        "  moves = get_moves(game.game_id)\n",
        "  game_moves.append({'game_id': game.game_id, 'moves': moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(game_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiXK2Dd2oxh1"
      },
      "outputs": [],
      "source": [
        "longest = pandas_result.query('moves == moves.max()')\n",
        "shortest = pandas_result.query('moves == moves.min()')\n",
        "\n",
        "long_game = df_games.filter(df_games.game_id == longest.game_id)\n",
        "short_game = df_games.filter(df_games.game_id == shortest.game_id)\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'game_id': longest.game_id, 'event': long_game.event.collect()[0][0], 'tournament_name': long_game.tournament_name.collect()[0][0], 'number_of_moves': longest.moves})\n",
        "result_list.append({'game_id': shortest.game_id, 'event': short_game.event.collect()[0][0], 'tournament_name': short_game.tournament_name.collect()[0][0], 'number_of_moves': shortest.moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBOdM-Izoy4n"
      },
      "outputs": [],
      "source": [
        "df6 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHI1ElGuo1RL"
      },
      "source": [
        "### 7Ô∏è‚É£ Most and Least rated Player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvhOTCFKppGc"
      },
      "outputs": [],
      "source": [
        "def get_rating(player_name):\n",
        "  # logic - get max of all rating group by player_name\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVfwfuhFo-Cl"
      },
      "outputs": [],
      "source": [
        "white_players = df_games.select('white').distinct().collect()\n",
        "black_players = df_games.select('black').distinct().collect()\n",
        "\n",
        "unique_players = set()\n",
        "for player in white_players:\n",
        "  unique_players.add(player.white)\n",
        "for player in black_players:\n",
        "  unique_players.add(player.black)\n",
        "\n",
        "result_list = []\n",
        "for player in unique_players:\n",
        "  rating = get_rating(player)\n",
        "  result_list.append({'player_name': player_name, 'elo': rating})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WeoPixpqhyc"
      },
      "outputs": [],
      "source": [
        "df7 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfLtg8RqnA8"
      },
      "source": [
        "### 8Ô∏è‚É£ 3rd Last Player with most Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0_Lm_MUquGT"
      },
      "outputs": [],
      "source": [
        "#TODO : incomplete\n",
        "loose_counts = df_games_notdraw.groupBy('loser').count().toPandas()\n",
        "\n",
        "last_third = loose_counts.sort_values('count').tail(3).values[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRzDU2omru02"
      },
      "outputs": [],
      "source": [
        "df8 = last_third.collet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vSBMsZrzAZ"
      },
      "source": [
        "### 9Ô∏è‚É£ How many times players with low rating won matches with their total win Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3sSLI3bsERv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iJ77mI5sIhB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDj76527sKrY"
      },
      "source": [
        "### 1Ô∏è‚É£0Ô∏è‚É£ Move Sequence for Each Player in a Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bWWbPFGsYkS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fUc0-Jofea"
      },
      "source": [
        "# Delete Section üîΩ { *using pandas* }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C03SsCBGpMHb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEgLu5B0o9m5"
      },
      "outputs": [],
      "source": [
        "pd_df_games = pd.read_csv(\"/content/chess/chess_wc_history_game_info.csv\")\n",
        "pd_df_moves = pd.read_csv(\"/content/chess/chess_wc_history_moves.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77CSEL2x5lCP"
      },
      "outputs": [],
      "source": [
        "# cal number of moves\n",
        "\n",
        "pd_df_moves[pd_df_moves.game_id == '86e0b7f5-7b94-4ae3-97c8-317371622795'].move_no.max()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}