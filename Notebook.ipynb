{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ2g9mu7XgaP"
      },
      "source": [
        "Update currently installed packages in your Google Colab Notebook's runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SBIOlIUVgCN",
        "outputId": "37e896e1-dcf8-4581-ac27-2e719dbddefb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [1 In\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [2 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [96.6 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,181 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,117 kB]\n",
            "Fetched 7,158 kB in 3s (2,143 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQlit156Ximj"
      },
      "source": [
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fR1jqw-bXTi9"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDZI6VnbXm3X"
      },
      "source": [
        "Next, we will download and unzip Apache Spark with Hadoop 2.7 to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tFRI6WpeXZEf"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XIrQT03XXbev"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm30koQnX3s6"
      },
      "source": [
        "Setup Environment variables for Java and Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MC4RxSkgX6GY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_bXY3DSZ8hu"
      },
      "source": [
        "Then we need to install and import the 'findspark' library that will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IA4WVVeiYHte"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4bobyzxZ9sq"
      },
      "source": [
        "Now, import SparkSession from pyspark.sql and create a SparkSession, which will be the entry point to Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W8KLz8knYU6t"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession \n",
        "\n",
        "spark = (SparkSession\n",
        "        .builder\n",
        "        .appName(\"datagrokr\")\n",
        "        .getOrCreate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzFZ2jYaGtl"
      },
      "source": [
        "Download all the files from Google drive link into the content directory of colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvnS2lHZ0qt",
        "outputId": "cd60111a-1c7d-472b-f4fd-9e88d615b8fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/chess/chess_schema.png',\n",
              " '/content/chess/chess_wc_history_game_info.csv',\n",
              " '/content/chess/chess_wc_history_moves.csv',\n",
              " '/content/chess/eco_codes.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7BWm7cocJS9"
      },
      "source": [
        "Create dataframes for each of the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ACah4HJkrgKF"
      },
      "outputs": [],
      "source": [
        "def head_view(dataframe):\n",
        "  dataframe.createOrReplaceTempView(\"tableHead\")\n",
        "  query = \"SELECT * FROM tableHead\"\n",
        "  df_head = spark.sql(query)\n",
        "  df_head.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I8NDjZiiL6y"
      },
      "source": [
        "Chess WC History Game Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HlkvPvxdbqNh"
      },
      "outputs": [],
      "source": [
        "df_games = spark.read.load(\"/content/chess/chess_wc_history_game_info.csv\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "# temp del\n",
        "df_games = df_games.limit(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkaBhJ3NiOLS"
      },
      "source": [
        "Chess WC History Moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c256aub7hm59"
      },
      "outputs": [],
      "source": [
        "df_moves = spark.read.load(\"/content/chess/chess_wc_history_moves.csv\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "# temp del\n",
        "df_moves = df_moves.limit(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuf3mxthumIO"
      },
      "source": [
        "WCh knock out(Sub-String with k.o. and KO ) are not included in main event. So, filter the event having Sub-String as k.o and KO in that specific Table Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZlqIkoh2nmrB"
      },
      "outputs": [],
      "source": [
        "df_games_notko = df_games.filter(~df_games.event.contains('k.o') | ~df_games.event.contains('KO'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u317P-naHtY"
      },
      "source": [
        "\n",
        "\n",
        "### 1️⃣ List of Winners of Each World champions Trophy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EgQYZX2Ch1wx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.functions import split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8EghM2Ml5V"
      },
      "source": [
        "Clean names of players - *select only first_name*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IlyjASmJRGzL"
      },
      "outputs": [],
      "source": [
        "def get_first_name(column):\n",
        "  return split(df_games_notko[column], ',').getItem(0)\n",
        "\n",
        "clean_names = ['white', 'black', 'winner', 'loser']\n",
        "for col in clean_names:\n",
        "  df_games_notko = df_games_notko.withColumn(col, get_first_name(col))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wwmTBZ9UAwlh"
      },
      "outputs": [],
      "source": [
        "def get_winner(dataframe):\n",
        "  white_players = dataframe.select('white').distinct().collect()\n",
        "  black_players = dataframe.select('black').distinct().collect()\n",
        "\n",
        "  players = set()\n",
        "  for player in white_players:\n",
        "    players.add(player.white)\n",
        "  for player in black_players:\n",
        "    players.add(player.black)\n",
        "\n",
        "  scores = dict.fromkeys(players, 0)\n",
        "  for game in dataframe.collect():\n",
        "    if game['result'] == 'draw':\n",
        "      scores[game['white']] += 1\n",
        "      scores[game['black']] += 1\n",
        "    elif game['result'] == '1-0':\n",
        "      scores[game['white']] += 1\n",
        "    else:\n",
        "      scores[game['black']] += 1\n",
        "      \n",
        "  return max(scores, key=scores.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ENdd1vxiaA4G"
      },
      "outputs": [],
      "source": [
        "all_tournaments = df_games_notko.toPandas().tournament_name.unique()\n",
        "\n",
        "result_list = []\n",
        "for tour in all_tournaments:\n",
        "  df_tour = df_games_notko.filter(df_games_notko.tournament_name == tour)\n",
        "  winner =  get_winner(df_tour)\n",
        "  result_list.append({'winner': winner, 'tournament_name': tour})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vE9-LkJyRDFy"
      },
      "outputs": [],
      "source": [
        "df1 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4nmi9zRqy6"
      },
      "source": [
        "### 2️⃣ List of Players with number of times they have won Tournament in descending order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "llldJ15sR33c"
      },
      "outputs": [],
      "source": [
        "df2 = df1.groupBy('winner').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAVqGu8VTrCv"
      },
      "source": [
        "### 3️⃣ Most and Least Popular eco move in world championship history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fo-qPfx2Tpej"
      },
      "outputs": [],
      "source": [
        "eco_counts = df_games_notko.groupBy('eco').count().toPandas()\n",
        "\n",
        "top = eco_counts.sort_values('count').head(1).values[0]\n",
        "end = eco_counts.sort_values('count').tail(1).values[0]\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'eco': end[0], 'eco_name': 'Double King Pawn Games', 'number_of_occurences': end[1]})\n",
        "result_list.append({'eco': top[0], 'eco_name': 'Sicilian Defence', 'number_of_occurences': top[1]})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3HLmDizM6S0i"
      },
      "outputs": [],
      "source": [
        "df3 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RjQhvbAJpd"
      },
      "source": [
        "### 4️⃣ Find the eco move with most winnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BavOoZeBAI7M"
      },
      "outputs": [],
      "source": [
        "df_games_notdraw = df_games_notko.filter(df_games_notko.result != '1/2-1/2')\n",
        "\n",
        "win_counts = df_games_notdraw.groupBy('eco').count().toPandas()\n",
        "\n",
        "top = win_counts.sort_values('count').head(1).values[0]\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'eco': top[0], 'eco_name': 'Sicilian Defence'})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1mv2zMeHEvJI"
      },
      "outputs": [],
      "source": [
        "df4 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEb9V6lXGWf6"
      },
      "source": [
        "### 5️⃣ Longest and shortest game ever played in a world championship in terms of move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "viTmrk7liKqO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nvBia1IDGjGZ"
      },
      "outputs": [],
      "source": [
        "def get_moves(game):\n",
        "  game_moves = df_moves.filter(df_moves.game_id == game)\n",
        "  return game_moves.agg(max('move_no')).collect()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7NlZzSTGiFBy"
      },
      "outputs": [],
      "source": [
        "game_moves = []\n",
        "\n",
        "for game in df_games.collect():\n",
        "  moves = get_moves(game.game_id)\n",
        "  game_moves.append({'game_id': game.game_id, 'moves': moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(game_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "9gYLmTuamV_d"
      },
      "outputs": [],
      "source": [
        "longest = pandas_result.query('moves == moves.max()')\n",
        "shortest = pandas_result.query('moves == moves.min()')\n",
        "\n",
        "long_game = df_games.filter(df_games.game_id == longest.game_id.values[0]).toPandas()\n",
        "short_game = df_games.filter(df_games.game_id == shortest.game_id.values[0]).toPandas()\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'game_id': longest.game_id.values[0], 'event': long_game.event.values[0], 'tournament_name': long_game.tournament_name.values[0], 'number_of_moves': longest.moves.values[0]})\n",
        "result_list.append({'game_id': shortest.game_id.values[0], 'event': short_game.event.values[0], 'tournament_name': short_game.tournament_name.values[0], 'number_of_moves': shortest.moves.values[0]})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "YcI_s92goKoS"
      },
      "outputs": [],
      "source": [
        "df5 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz92TIrzoUaN"
      },
      "source": [
        "### 6️⃣ Shortest and Longest Draw game ever Played"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "khkk__1XogdD"
      },
      "outputs": [],
      "source": [
        "game_moves = []\n",
        "\n",
        "games_drawn = df_games.filter(df_games.result == '1/2-1/2')\n",
        "\n",
        "for game in games_drawn.collect():\n",
        "  moves = get_moves(game.game_id)\n",
        "  game_moves.append({'game_id': game.game_id, 'moves': moves})\n",
        "\n",
        "pandas_result = pd.DataFrame(game_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "QiXK2Dd2oxh1"
      },
      "outputs": [],
      "source": [
        "longest = pandas_result.query('moves == moves.max()')\n",
        "shortest = pandas_result.query('moves == moves.min()')\n",
        "\n",
        "long_game = df_games.filter(df_games.game_id == longest.game_id.values[0]).toPandas()\n",
        "short_game = df_games.filter(df_games.game_id == shortest.game_id.values[0]).toPandas()\n",
        "\n",
        "result_list = []\n",
        "result_list.append({'game_id': longest.game_id.values[0], 'event': long_game.event.values[0], 'tournament_name': long_game.tournament_name.values[0], 'number_of_moves': longest.moves.values[0]})\n",
        "result_list.append({'game_id': shortest.game_id.values[0], 'event': short_game.event.values[0], 'tournament_name': short_game.tournament_name.values[0], 'number_of_moves': shortest.moves.values[0]})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "FBOdM-Izoy4n"
      },
      "outputs": [],
      "source": [
        "df6 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHI1ElGuo1RL"
      },
      "source": [
        "### 7️⃣ Most and Least rated Player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "fvhOTCFKppGc"
      },
      "outputs": [],
      "source": [
        "def get_rating(player_name):\n",
        "  df_player = df_games_notdraw.filter(df_games_notdraw.winner == player_name)\n",
        "  winner_max = df_player.agg({'winner_elo': 'max'}).collect()[0][0]\n",
        "  if not str(winner_max).isdigit():\n",
        "    winner_max = None\n",
        "  df_player = df_games_notdraw.filter(df_games_notdraw.loser == player_name)\n",
        "  loser_max = df_player.agg({'loser_elo': 'max'}).collect()[0][0]\n",
        "  if not str(loser_max).isdigit():\n",
        "    loser_max = None\n",
        "  if winner_max is None and loser_max is None:\n",
        "    return 0\n",
        "  elif winner_max is None and loser_max is not None:\n",
        "    return loser_max\n",
        "  elif winner_max is not None and loser_max is None:\n",
        "    return winner_max\n",
        "  else:\n",
        "    return max(winner_max, loser_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "QVfwfuhFo-Cl"
      },
      "outputs": [],
      "source": [
        "white_players = df_games.select('white').distinct().collect()\n",
        "black_players = df_games.select('black').distinct().collect()\n",
        "\n",
        "unique_players = set()\n",
        "for player in white_players:\n",
        "  unique_players.add(player.white)\n",
        "for player in black_players:\n",
        "  unique_players.add(player.black)\n",
        "\n",
        "result_list = []\n",
        "for player in unique_players:\n",
        "  rating = get_rating(player)\n",
        "  result_list.append({'player_name': player, 'elo': rating})\n",
        "\n",
        "pandas_result = pd.DataFrame(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "2WeoPixpqhyc"
      },
      "outputs": [],
      "source": [
        "df7 = spark.createDataFrame(pandas_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfLtg8RqnA8"
      },
      "source": [
        "### 8️⃣ 3rd Last Player with most Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "h0_Lm_MUquGT"
      },
      "outputs": [],
      "source": [
        "loose_counts = df_games_notdraw.groupBy('loser').count().toPandas()\n",
        "\n",
        "last_third = loose_counts.sort_values('count').tail(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "eRzDU2omru02"
      },
      "outputs": [],
      "source": [
        "df8 = last_third.loser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vSBMsZrzAZ"
      },
      "source": [
        "### 9️⃣ How many times players with low rating won matches with their total win Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "2iJ77mI5sIhB"
      },
      "outputs": [],
      "source": [
        "df9 = df_games_notdraw.filter(df_games_notdraw.loser_elo > df_games_notdraw.winner_elo).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDj76527sKrY"
      },
      "source": [
        "### 1️⃣0️⃣ Move Sequence for Each Player in a Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bWWbPFGsYkS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTdJ9pwfR4ez"
      },
      "source": [
        "Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee_I271HHaK2",
        "outputId": "1a07bb5c-6674-4a8d-9af0-ccfaf1157309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "7vTsN29a8jpe"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ihhbuaODS11Z"
      },
      "outputs": [],
      "source": [
        "save_path = '/My Drive/DE_SOLUTION_sura_karthikeya'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "-JDtTyHBG0Uw"
      },
      "outputs": [],
      "source": [
        "def save_to_drive(dataframe, file_name):\n",
        "  save_file = dataframe.toPandas()\n",
        "  save_file.to_csv(f'{file_name}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "vYL6Eg_JR9Tp"
      },
      "outputs": [],
      "source": [
        "save_to_drive(df1, 'df1')\n",
        "save_to_drive(df2, 'df2')\n",
        "save_to_drive(df3, 'df3')\n",
        "save_to_drive(df4, 'df4')\n",
        "save_to_drive(df5, 'df5')\n",
        "save_to_drive(df6, 'df6')\n",
        "save_to_drive(df7, 'df7')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4u317P-naHtY",
        "Fr4nmi9zRqy6",
        "iAVqGu8VTrCv",
        "R7RjQhvbAJpd",
        "Vz92TIrzoUaN",
        "QvfLtg8RqnA8",
        "b4vSBMsZrzAZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}